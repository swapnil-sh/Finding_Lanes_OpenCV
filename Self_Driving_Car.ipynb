{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finding Lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread('test_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a copy of image and coverting the image to grayscale for better analysis\n",
    "\n",
    "lane_image = np.copy(image)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# we are using Gaussian Blur to blur the image so that the noise gets reduced\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "\n",
    "cv2.imshow('result',blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will be applying Canny method to identify the edges\n",
    "\n",
    "An edge corresponds to a region in an image where there is a sharp change in the intensity or a sharp change in colour between adjacent pixels in the image.\n",
    "The change in brightness over  series of pixels is the Gradient.\n",
    "\n",
    "A strong Gradient indicates a steep change wehereas a small gradient indicates a shallow change\n",
    "\n",
    "An image is composed pf pixels and can be therefore be read as a matrix an array of pixel intensities.\n",
    "\n",
    "We can also represent an image in 2-D coordinate space where X-axis traversesthe images width (#coloumns) and Y-axis traverses images height (#rows)\n",
    "\n",
    "The canny function will perform a derivateive on our function in both x and y directions thereby measuring the change in intensity with respect to adjacent pixels. It computes the gradient in all directions of our blurred image and is then going to trace our strongest gradients as a series of white pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_image = cv2.Canny(blur,50,50)\n",
    "\n",
    "cv2.imshow('result',canny_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Interest\n",
    "\n",
    "We are going to specify a region of interest in our image that we are going to use to detect landmines.We will isolate the region of interest and mask everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(image):\n",
    "    height = image.shape[0]\n",
    "    polygons = np.array([[(200,height),(1100,height),(550,250)]]) #creating triangle or polygon retracing the path from our image\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.fillPoly(mask,polygons,255)\n",
    "    masked_image = cv2.bitwise_and(image,mask) #we are doing bitwise AND between two image matrices of canny image and triangle image tht we created \n",
    "    return masked_image\n",
    "\n",
    "cropped_image = region_of_interest(canny_image)\n",
    "cv2.imshow('result',cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lines(image,lines):\n",
    "    line_image = np.zeros_like(image)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2 = line.reshape(4)\n",
    "            cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coordinates(image,line_parameters):\n",
    "    \n",
    "\n",
    "    slope, intercept = line_parameters\n",
    "    y1 = image.shape[0]\n",
    "    y2 = int(y1*(3/5))\n",
    "    x1 = int((y1-intercept)/slope)\n",
    "    x2 = int((y2-intercept)/slope)\n",
    "    return np.array((x1,y1,x2,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(image,lines):\n",
    "    left_fit = []\n",
    "    right_fit = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line.reshape(4)\n",
    "        parameters = np.polyfit((x1,x2),(y1,y2),1)\n",
    "        slope = parameters[0]\n",
    "        intercept = parameters[1]\n",
    "        if slope < 0:\n",
    "            left_fit.append((slope,intercept))\n",
    "        else:\n",
    "            right_fit.append((slope,intercept))\n",
    "            \n",
    "    if left_fit:\n",
    "        left_fit_average = np.average(left_fit, axis=0)\n",
    "       # print(left_fit_average, 'left')\n",
    "        left_line = make_coordinates(image, left_fit_average)\n",
    "    if right_fit:\n",
    "        right_fit_average = np.average(right_fit, axis=0)\n",
    "        #print(right_fit_average, 'right')\n",
    "        right_line = make_coordinates(image, right_fit_average)\n",
    "\n",
    "    return np.array([left_line,right_line])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Detection - Hough  Transform\n",
    "\n",
    "A technique that will detect stright lines in an image and hence identify the lane line. This technique is known as the Hough Transform.\n",
    "\n",
    "There are multiple equations with which we can represent a line. Two of them are \n",
    "\n",
    "1. y = mx +b\n",
    "2. xcos(o)+ysin(o) = p\n",
    "\n",
    "    * p is the perpendicular distance from the origin to the line.\n",
    "    * o is the angle formed by this perpendicular line and horizontal axis.\n",
    "    \n",
    "## Intuition :\n",
    "\n",
    "* In an image space, a line is plotted as x vs y or plotted as y = mx+b or xcos(o)+ysin(o) = p\n",
    "* In parameter space (hough), a line is represented by a point \"m vs b\" or \"o vs p\"\n",
    "* Each line is represented as a single point with (m,b) coordinates or (p,o) parameters.\n",
    "\n",
    "### If we have a point in our \"x vs y\" space and we have a family of lines that pass through that point which will be having different values for m and b, in hough space (m vs b) if we plot all the values of m and b for all the lines passing through our point, we will get a stright line.\n",
    "\n",
    "We cannot represent a vertical line in hough space as the value of slope will be infinity.\n",
    "Therefor, we will represent pur line/point in Polar Coordinate System in terms of o and p (row snd theta) instead of Carteian System.\n",
    "\n",
    "### xcos(o)+ysin(o) = p\n",
    "\n",
    "\n",
    "For each line passing through our point in image space with different values of o and p,If we plot O vs p in hough space we will be getting a sinosoidal curve.\n",
    "\n",
    "A line can be detected by finding the number of intersections between curves. \n",
    "The more curves intersecting means the line represented by that intersection passes/crosses more points.\n",
    "\n",
    "After plotting curves we will divide our hough space in grid system and find a box with majority vote .i.e in which the maximum number of intersections are occuring. We will get a value  of p and o and that line represented using that values will be the line of best fit.\n",
    "\n",
    "Therefore, we are trying to find which line best fits our data or best describes pur points.\n",
    "\n",
    "So here we will try to find a line that best defines the edge points in our gradient image.\n",
    "\n",
    "GRID = Acumulator Array\n",
    "We will get more precision if we have more no of bins in our grid.\n",
    "\n",
    "THRESHOLD = Minimum no of intersections/votes needed to accept a candidate line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(cropped_image,2,np.pi/180,100,np.array([]),minLineLength=40,maxLineGap=5)\n",
    "\n",
    "averaged_lines = average_slope_intercept(lane_image,lines)\n",
    "line_image = display_lines(lane_image,averaged_lines)\n",
    "\n",
    "combo_image = cv2.addWeighted(lane_image,0.8,line_image,1,1)\n",
    "\n",
    "cv2.imshow('result',combo_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Lanes in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"test2.mp4\")\n",
    "while(cap.isOpened()):\n",
    "    _,frame = cap.read() #decode evry video frame\n",
    "    canny_image = cv2.Canny(frame,50,50)\n",
    "    cropped_image = region_of_interest(canny_image)\n",
    "    lines = cv2.HoughLinesP(cropped_image,2,np.pi/180,100,np.array([]),minLineLength=40,maxLineGap=5)\n",
    "    averaged_lines = average_slope_intercept(frame,lines)\n",
    "    line_image = display_lines(frame,averaged_lines)\n",
    "\n",
    "    combo_image = cv2.addWeighted(frame,0.8,line_image,1,1)\n",
    "\n",
    "    cv2.imshow('result',combo_image)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
